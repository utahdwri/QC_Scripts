{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77745f4f-1285-47e2-8d05-55605c068214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlalchemy in c:\\users\\pbenko\\appdata\\local\\anaconda3\\lib\\site-packages (2.0.34)\n",
      "Requirement already satisfied: pyodbc in c:\\users\\pbenko\\appdata\\local\\anaconda3\\lib\\site-packages (5.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\pbenko\\appdata\\local\\anaconda3\\lib\\site-packages (from sqlalchemy) (4.11.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\pbenko\\appdata\\local\\anaconda3\\lib\\site-packages (from sqlalchemy) (3.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sqlalchemy pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e8a27f2-447b-477c-a4d8-47704ae59136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory: C:\\Users\\pbenko\\Documents\\20250213_distribution_data\\data\n",
      "✅ Trying to load data from SQL...\n",
      "✅ Data loaded successfully. Rows: 74788, Columns: 374\n",
      "✅ Identified 372 daily columns.\n",
      "📊 Starting IQR calculation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Stations & Years: 100%|██████████| 74677/74677 [3:17:43<00:00,  6.29it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of IQR Results (first few rows):\n",
      "   STATION_ID RECORD_YEAR                               RV_0401  \\\n",
      "0           1        1950    {'Q1': 0.0, 'Q3': 0.0, 'IQR': 0.0}   \n",
      "1           1        1951    {'Q1': 0.0, 'Q3': 0.0, 'IQR': 0.0}   \n",
      "2           1        1952                                   NaN   \n",
      "3           1        1953  {'Q1': 36.0, 'Q3': 36.0, 'IQR': 0.0}   \n",
      "4           1        1954    {'Q1': 0.0, 'Q3': 0.0, 'IQR': 0.0}   \n",
      "\n",
      "                                RV_0402                               RV_0403  \\\n",
      "0    {'Q1': 0.0, 'Q3': 0.0, 'IQR': 0.0}    {'Q1': 0.0, 'Q3': 0.0, 'IQR': 0.0}   \n",
      "1    {'Q1': 0.0, 'Q3': 0.0, 'IQR': 0.0}    {'Q1': 0.0, 'Q3': 0.0, 'IQR': 0.0}   \n",
      "2                                   NaN                                   NaN   \n",
      "3  {'Q1': 31.0, 'Q3': 31.0, 'IQR': 0.0}  {'Q1': 36.0, 'Q3': 36.0, 'IQR': 0.0}   \n",
      "4    {'Q1': 0.0, 'Q3': 0.0, 'IQR': 0.0}    {'Q1': 0.0, 'Q3': 0.0, 'IQR': 0.0}   \n",
      "\n",
      "                                RV_0404                               RV_0405  \\\n",
      "0    {'Q1': 0.0, 'Q3': 0.0, 'IQR': 0.0}    {'Q1': 0.0, 'Q3': 0.0, 'IQR': 0.0}   \n",
      "1    {'Q1': 0.0, 'Q3': 0.0, 'IQR': 0.0}    {'Q1': 0.0, 'Q3': 0.0, 'IQR': 0.0}   \n",
      "2                                   NaN                                   NaN   \n",
      "3  {'Q1': 33.0, 'Q3': 33.0, 'IQR': 0.0}  {'Q1': 36.0, 'Q3': 36.0, 'IQR': 0.0}   \n",
      "4    {'Q1': 0.0, 'Q3': 0.0, 'IQR': 0.0}    {'Q1': 0.0, 'Q3': 0.0, 'IQR': 0.0}   \n",
      "\n",
      "                                RV_0406                               RV_0407  \\\n",
      "0    {'Q1': 0.0, 'Q3': 0.0, 'IQR': 0.0}    {'Q1': 0.0, 'Q3': 0.0, 'IQR': 0.0}   \n",
      "1    {'Q1': 0.0, 'Q3': 0.0, 'IQR': 0.0}    {'Q1': 0.0, 'Q3': 0.0, 'IQR': 0.0}   \n",
      "2                                   NaN                                   NaN   \n",
      "3  {'Q1': 35.0, 'Q3': 35.0, 'IQR': 0.0}  {'Q1': 36.0, 'Q3': 36.0, 'IQR': 0.0}   \n",
      "4    {'Q1': 0.0, 'Q3': 0.0, 'IQR': 0.0}    {'Q1': 0.0, 'Q3': 0.0, 'IQR': 0.0}   \n",
      "\n",
      "                                RV_0408  ... RV_0220 RV_0221 RV_0222 RV_0223  \\\n",
      "0    {'Q1': 0.0, 'Q3': 0.0, 'IQR': 0.0}  ...     NaN     NaN     NaN     NaN   \n",
      "1    {'Q1': 0.0, 'Q3': 0.0, 'IQR': 0.0}  ...     NaN     NaN     NaN     NaN   \n",
      "2                                   NaN  ...     NaN     NaN     NaN     NaN   \n",
      "3  {'Q1': 38.0, 'Q3': 38.0, 'IQR': 0.0}  ...     NaN     NaN     NaN     NaN   \n",
      "4    {'Q1': 0.0, 'Q3': 0.0, 'IQR': 0.0}  ...     NaN     NaN     NaN     NaN   \n",
      "\n",
      "  RV_0224 RV_0225 RV_0226 RV_0227 RV_0228 RV_0229  \n",
      "0     NaN     NaN     NaN     NaN     NaN     NaN  \n",
      "1     NaN     NaN     NaN     NaN     NaN     NaN  \n",
      "2     NaN     NaN     NaN     NaN     NaN     NaN  \n",
      "3     NaN     NaN     NaN     NaN     NaN     NaN  \n",
      "4     NaN     NaN     NaN     NaN     NaN     NaN  \n",
      "\n",
      "[5 rows x 368 columns]\n",
      "Saving IQR results to: C:\\Users\\pbenko\\Documents\\20250213_distribution_data\\data\\combined_iqr_results.csv\n",
      "✅ IQR results saved to 'C:\\Users\\pbenko\\Documents\\20250213_distribution_data\\data\\combined_iqr_results.csv'.\n",
      "Saving invalid data to: C:\\Users\\pbenko\\Documents\\20250213_distribution_data\\data\\invalid_data_log.csv\n",
      "⚠️ Invalid data saved to 'C:\\Users\\pbenko\\Documents\\20250213_distribution_data\\data\\invalid_data_log.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "from tqdm import tqdm  # Standard tqdm for text-based progress bar\n",
    "\n",
    "# Define the connection parameters\n",
    "server = 'wrt-sql-prod'\n",
    "database = 'dvrtDB'\n",
    "username = 'wrtsqlq'\n",
    "password = 'guest'\n",
    "\n",
    "# Create SQLAlchemy engine\n",
    "connection_string = f\"mssql+pyodbc://{username}:{password}@{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Directory to save the results\n",
    "output_directory = r\"C:\\Users\\pbenko\\Documents\\20250213_distribution_data\\data\"\n",
    "print(f\"Output directory: {output_directory}\")  # Debugging print\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_directory):\n",
    "    print(\"Creating output directory...\")  # Debugging print\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# List to store invalid data (empty groups/columns)\n",
    "invalid_data = []\n",
    "\n",
    "try:\n",
    "    # SQL Query to load all data\n",
    "    query = \"SELECT * FROM dbo.DAILY_RECORDS\"\n",
    "\n",
    "    # Load the full dataset\n",
    "    print(\"✅ Trying to load data from SQL...\")\n",
    "    df = pd.read_sql(query, engine)\n",
    "    print(f\"✅ Data loaded successfully. Rows: {df.shape[0]}, Columns: {df.shape[1]}\")\n",
    "\n",
    "    # Identify columns related to days (RV_0101, RV_0102, ..., RV_1231)\n",
    "    daily_cols = [col for col in df.columns if col.startswith(\"RV_\")]\n",
    "    print(f\"✅ Identified {len(daily_cols)} daily columns.\")\n",
    "\n",
    "    # Initialize a list for storing IQR results\n",
    "    iqr_results = []\n",
    "\n",
    "    # Start processing with a progress bar (text-based)\n",
    "    print(\"📊 Starting IQR calculation...\")\n",
    "    \n",
    "    # Wrap the iteration in tqdm to display a progress bar\n",
    "    for (station, year), group in tqdm(df.groupby([\"STATION_ID\", \"RECORD_YEAR\"]), desc=\"Processing Stations & Years\", total=df.groupby([\"STATION_ID\", \"RECORD_YEAR\"]).ngroups):\n",
    "        # Skip empty group (no data for the station-year combination)\n",
    "        if group.empty:\n",
    "            invalid_data.append({\"STATION_ID\": station, \"RECORD_YEAR\": year, \"reason\": \"No data\"})\n",
    "            continue\n",
    "        \n",
    "        # Filter out day columns with all NaN values\n",
    "        valid_cols = [col for col in daily_cols if group[col].dropna().size > 0]\n",
    "        \n",
    "        if not valid_cols:\n",
    "            # Skip if no valid day columns for this station-year\n",
    "            invalid_data.append({\"STATION_ID\": station, \"RECORD_YEAR\": year, \"reason\": \"No valid day data\"})\n",
    "            continue\n",
    "        \n",
    "        # Create a dictionary for storing IQR results for the current station and year\n",
    "        iqr_for_station_year = {\n",
    "            \"STATION_ID\": station,\n",
    "            \"RECORD_YEAR\": year\n",
    "        }\n",
    "        \n",
    "        # Compute IQR for each valid day column\n",
    "        for col in valid_cols:\n",
    "            # Drop NaN values and compute the IQR\n",
    "            valid_data = group[col].dropna()\n",
    "            \n",
    "            # Calculate Q1, Q3, and IQR\n",
    "            Q1 = np.percentile(valid_data, 25)  # 25th percentile\n",
    "            Q3 = np.percentile(valid_data, 75)  # 75th percentile\n",
    "            IQR = Q3 - Q1  # Interquartile Range\n",
    "            \n",
    "            iqr_for_station_year[col] = {\"Q1\": Q1, \"Q3\": Q3, \"IQR\": IQR}\n",
    "        \n",
    "        # Append results for this station and year\n",
    "        iqr_results.append(iqr_for_station_year)\n",
    "\n",
    "    # Convert the list of dictionaries into a DataFrame for easier analysis\n",
    "    iqr_df = pd.DataFrame(iqr_results)\n",
    "\n",
    "    # Print the first few rows of IQR results for debugging\n",
    "    print(\"Sample of IQR Results (first few rows):\")\n",
    "    print(iqr_df.head())  # Debugging print\n",
    "\n",
    "    # Save the IQR results to CSV\n",
    "    output_file = os.path.join(output_directory, \"combined_iqr_results.csv\")\n",
    "    print(f\"Saving IQR results to: {output_file}\")  # Debugging print\n",
    "    iqr_df.to_csv(output_file, index=False)\n",
    "\n",
    "    print(f\"✅ IQR results saved to '{output_file}'.\")\n",
    "\n",
    "    # If there is invalid data (no valid day columns for a station-year), save it to a separate CSV\n",
    "    if invalid_data:\n",
    "        invalid_df = pd.DataFrame(invalid_data)\n",
    "        invalid_data_file = os.path.join(output_directory, \"invalid_data_log.csv\")\n",
    "        print(f\"Saving invalid data to: {invalid_data_file}\")  # Debugging print\n",
    "        invalid_df.to_csv(invalid_data_file, index=False)\n",
    "        print(f\"⚠️ Invalid data saved to '{invalid_data_file}'.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4b3e5c-27a5-4494-b42b-37c6951ccd95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
