{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d35b4ab-7ab1-49f8-afa1-a0dfd233f934",
   "metadata": {},
   "source": [
    "### Similar Station Names with Reservior Script Threshold at 0.7 matrix csv output files as thing with similar name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1212af-d454-4a3b-be02-06c067410cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "\n",
    "# Function to preprocess names\n",
    "def preprocess_name(name):\n",
    "    name = name.upper()\n",
    "    name = re.sub(r'\\bRES\\.?\\b', 'RESERVOIR', name)\n",
    "    name = re.sub(r'\\bRSVR\\.?\\b', 'RESERVOIR', name)\n",
    "    name = re.sub(r'\\(.*?\\)|[^A-Z0-9\\s]', '', name)\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "    return name\n",
    "\n",
    "# Set the similarity threshold (hardcoded)\n",
    "similarity_threshold = 0.7  # Adjust this value as needed\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'Things.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure required columns exist\n",
    "required_columns = ['thing_name', 'thing_siteType', 'system_name']\n",
    "for col in required_columns:\n",
    "    if col not in data.columns:\n",
    "        raise ValueError(f\"The CSV file must contain a '{col}' column.\")\n",
    "\n",
    "# Apply preprocessing to all names\n",
    "data['processed_name'] = data['thing_name'].apply(preprocess_name)\n",
    "\n",
    "# Initialize an identifier column\n",
    "data['identifier'] = None\n",
    "\n",
    "# Create a dictionary to store generalized names\n",
    "generalized_names_map = {}\n",
    "\n",
    "# Process data grouped by 'thing_siteType'\n",
    "current_id = 0\n",
    "for site_type, group in data.groupby('thing_siteType'):\n",
    "    # Compute TF-IDF vectors for the processed names within the same group\n",
    "    vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1, 2))\n",
    "    tfidf_matrix = vectorizer.fit_transform(group['processed_name'])\n",
    "    \n",
    "    # Compute cosine similarity matrix\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix)\n",
    "    \n",
    "    # Assign unique identifiers based on similarity\n",
    "    group_identifiers = [None] * len(group)\n",
    "    group_index = group.index.tolist()  # Get original index from the group\n",
    "    for i in range(len(group)):\n",
    "        if group_identifiers[i] is None:  # If not already assigned\n",
    "            current_id += 1\n",
    "            group_identifiers[i] = current_id\n",
    "            similar_names = [group.iloc[i]['processed_name']]\n",
    "            for j in range(i + 1, len(group)):\n",
    "                if cosine_sim[i, j] > similarity_threshold:\n",
    "                    group_identifiers[j] = current_id\n",
    "                    similar_names.append(group.iloc[j]['processed_name'])\n",
    "            # Assign the common base name for this identifier\n",
    "            generalized_name = \" \".join(set(similar_names))\n",
    "            generalized_names_map[current_id] = generalized_name\n",
    "    \n",
    "    # Update the identifiers in the original DataFrame\n",
    "    data.loc[group_index, 'identifier'] = group_identifiers\n",
    "\n",
    "# Replace processed_name with the generalized name based on identifier\n",
    "data['processed_name'] = data['identifier'].map(generalized_names_map)\n",
    "\n",
    "# Split data into two categories\n",
    "identifier_counts = data['identifier'].value_counts()\n",
    "\n",
    "similar_data = data[data['identifier'].isin(identifier_counts[identifier_counts > 1].index)]\n",
    "unique_data = data[data['identifier'].isin(identifier_counts[identifier_counts == 1].index)]\n",
    "\n",
    "# Sort the subsets\n",
    "similar_data = similar_data.sort_values(by=['thing_name', 'identifier', 'system_name'], ascending=True)\n",
    "unique_data = unique_data.sort_values(by=['thing_name', 'identifier', 'system_name'], ascending=True)\n",
    "\n",
    "# Save the subsets to separate CSV files\n",
    "similar_output_path = 'Things_with_similar_names.csv'\n",
    "unique_output_path = 'Things_with_unique_names.csv'\n",
    "\n",
    "similar_data.to_csv(similar_output_path, index=False)\n",
    "unique_data.to_csv(unique_output_path, index=False)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Processed files saved: \\n - {similar_output_path}\\n - {unique_output_path}\")\n",
    "\n",
    "# Count rows in each subset\n",
    "num_similar_names = len(similar_data)\n",
    "num_unique_names = len(unique_data)\n",
    "\n",
    "print(\"Number of similar names:\", num_similar_names)\n",
    "print(\"Number of unique names:\", num_unique_names)\n",
    "\n",
    "\n",
    "\n",
    "# Create a dictionary to store similarity matrices\n",
    "similarity_matrices = {}\n",
    "\n",
    "# Process data grouped by 'thing_siteType'\n",
    "for site_type, group in data.groupby('thing_siteType'):\n",
    "    # Compute TF-IDF vectors for the processed names within the same group\n",
    "    vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1, 2))\n",
    "    tfidf_matrix = vectorizer.fit_transform(group['processed_name'])\n",
    "    \n",
    "    # Compute cosine similarity matrix\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix)\n",
    "    \n",
    "    # Convert cosine similarity matrix to a DataFrame\n",
    "    similarity_matrix_df = pd.DataFrame(\n",
    "        cosine_sim,\n",
    "        index=group['thing_name'],\n",
    "        columns=group['thing_name']\n",
    "    )\n",
    "    \n",
    "    # Store the similarity matrix for this site type\n",
    "    similarity_matrices[site_type] = similarity_matrix_df\n",
    "    \n",
    "    # Save to a CSV file for this group\n",
    "    output_path = f\"Similarity_Matrix_{site_type}.csv\"\n",
    "    similarity_matrix_df.to_csv(output_path)\n",
    "    print(f\"Saved similarity matrix for site type '{site_type}' to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd16c83b-483e-462c-9498-acd2e41557e6",
   "metadata": {},
   "source": [
    "### Similar Station Names w/o Reservior Script Threshold at 0.7 matrix csv output files as thing with similar name no reservior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874f45ff-2ebf-48de-93dd-a779323f1ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "\n",
    "# Function to preprocess names\n",
    "def preprocess_name(name):\n",
    "    name = name.upper()\n",
    "    name = re.sub(r'\\bRES\\.?\\b', 'RESERVOIR', name)\n",
    "    name = re.sub(r'\\bRSVR\\.?\\b', 'RESERVOIR', name)\n",
    "    name = re.sub(r'\\(.*?\\)|[^A-Z0-9\\s]', '', name)\n",
    "    name = re.sub(r'\\s+', ' ', name).strip()\n",
    "    return name\n",
    "\n",
    "# Set the similarity threshold\n",
    "similarity_threshold = 0.7\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'Things.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure required columns exist\n",
    "required_columns = ['thing_name', 'thing_siteType', 'system_name']\n",
    "for col in required_columns:\n",
    "    if col not in data.columns:\n",
    "        raise ValueError(f\"The CSV file must contain a '{col}' column.\")\n",
    "\n",
    "# Apply preprocessing to all names\n",
    "data['processed_name'] = data['thing_name'].apply(preprocess_name)\n",
    "\n",
    "# Initialize an identifier column\n",
    "data['identifier'] = None\n",
    "generalized_names_map = {}\n",
    "current_id = 0\n",
    "\n",
    "# Grouping and similarity calculation\n",
    "for site_type, group in data.groupby('thing_siteType'):\n",
    "    vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1, 2))\n",
    "    tfidf_matrix = vectorizer.fit_transform(group['processed_name'])\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "    group_identifiers = [None] * len(group)\n",
    "    group_index = group.index.tolist()\n",
    "\n",
    "    for i in range(len(group)):\n",
    "        if group_identifiers[i] is None:\n",
    "            current_id += 1\n",
    "            group_identifiers[i] = current_id\n",
    "            similar_names = [group.iloc[i]['processed_name']]\n",
    "            for j in range(i + 1, len(group)):\n",
    "                if cosine_sim[i, j] > similarity_threshold:\n",
    "                    group_identifiers[j] = current_id\n",
    "                    similar_names.append(group.iloc[j]['processed_name'])\n",
    "            generalized_name = \" \".join(set(similar_names))\n",
    "            generalized_names_map[current_id] = generalized_name\n",
    "\n",
    "    data.loc[group_index, 'identifier'] = group_identifiers\n",
    "\n",
    "# Replace processed_name with generalized name based on identifier\n",
    "data['processed_name'] = data['identifier'].map(generalized_names_map)\n",
    "\n",
    "# Split into similar and unique groups\n",
    "identifier_counts = data['identifier'].value_counts()\n",
    "similar_data = data[data['identifier'].isin(identifier_counts[identifier_counts > 1].index)]\n",
    "unique_data = data[data['identifier'].isin(identifier_counts[identifier_counts == 1].index)]\n",
    "\n",
    "# Filter out names with 'Reservoir' in original thing_name (case-insensitive)\n",
    "similar_data_no_reservoir = similar_data[~similar_data['thing_name'].str.upper().str.contains(\"RESERVOIR\")]\n",
    "\n",
    "# Sort\n",
    "similar_data = similar_data.sort_values(by=['thing_name', 'identifier', 'system_name'])\n",
    "unique_data = unique_data.sort_values(by=['thing_name', 'identifier', 'system_name'])\n",
    "similar_data_no_reservoir = similar_data_no_reservoir.sort_values(by=['thing_name', 'identifier', 'system_name'])\n",
    "\n",
    "# Output file paths\n",
    "similar_output_path = 'Things_with_similar_names.csv'\n",
    "unique_output_path = 'Things_with_unique_names.csv'\n",
    "no_reservoir_output_path = 'Things_with_similar_names_no_reservoir.csv'\n",
    "\n",
    "# Save files\n",
    "similar_data.to_csv(similar_output_path, index=False)\n",
    "unique_data.to_csv(unique_output_path, index=False)\n",
    "similar_data_no_reservoir.to_csv(no_reservoir_output_path, index=False)\n",
    "\n",
    "print(f\"Processed files saved:\\n - {similar_output_path}\\n - {unique_output_path}\\n - {no_reservoir_output_path}\")\n",
    "print(\"Number of similar names:\", len(similar_data))\n",
    "print(\"Number of unique names:\", len(unique_data))\n",
    "print(\"Number of similar names without 'Reservoir':\", len(similar_data_no_reservoir))\n",
    "\n",
    "# Save similarity matrices per site_type\n",
    "similarity_matrices = {}\n",
    "for site_type, group in data.groupby('thing_siteType'):\n",
    "    vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1, 2))\n",
    "    tfidf_matrix = vectorizer.fit_transform(group['processed_name'])\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "    similarity_matrix_df = pd.DataFrame(\n",
    "        cosine_sim,\n",
    "        index=group['thing_name'],\n",
    "        columns=group['thing_name']\n",
    "    )\n",
    "    similarity_matrices[site_type] = similarity_matrix_df\n",
    "\n",
    "    output_path = f\"Similarity_Matrix_{site_type}.csv\"\n",
    "    similarity_matrix_df.to_csv(output_path)\n",
    "    print(f\"Saved similarity matrix for site type '{site_type}' to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622716ea-69db-4fb0-ba9a-23e800343235",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
