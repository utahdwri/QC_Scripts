{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89424ede-727f-48db-b7f2-0ed1295fe9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Stations: 100%|██████████| 839/839 [41:55<00:00,  3.00s/station]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final merged data saved as merged_2.0_840_station_metadata_flagging_criteria_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import time\n",
    "from tqdm import tqdm  # Progress bar\n",
    "\n",
    "# Load metadata CSV\n",
    "metadata_path = \"C:\\\\Users\\\\pbenko\\\\Documents\\\\SQL saved scripts\\\\meta_data_for_all_active_systems_for_calculation_20250401(CSV).csv\"\n",
    "metadata_df = pd.read_csv(metadata_path, dtype={\"STATION_ID\": str})  # Ensure STATION_ID is a string\n",
    "\n",
    "# Get the first 840 rows of metadata\n",
    "filtered_metadata = metadata_df.head(840).copy()\n",
    "\n",
    "# Extract STATION_IDs from the first 839 rows\n",
    "site_ids = filtered_metadata[\"STATION_ID\"].tolist()\n",
    "\n",
    "# Initialize results DataFrame\n",
    "df_results = pd.DataFrame()\n",
    "\n",
    "# Start progress bar\n",
    "start_time = time.time()\n",
    "with tqdm(total=len(site_ids), desc=\"Processing Stations\", unit=\"station\") as pbar:\n",
    "    for i, DivrtID in enumerate(site_ids, start=1):\n",
    "        end_date = datetime.today().strftime(\"%Y-%m-%d\")  # Get today's date in YYYY-MM-DD format\n",
    "        api_url = f\"https://www.waterrights.utah.gov/dvrtdb/daily-chart.asp?station_id={DivrtID}&end_date={end_date}&f=json\"\n",
    "\n",
    "        response = requests.get(api_url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if \"data\" in data:\n",
    "                df = pd.DataFrame(data[\"data\"], columns=[\"date\", \"value\"])\n",
    "                df.rename(columns={\"date\": \"Date\", \"value\": \"DISCHARGE\"}, inplace=True)\n",
    "                df[\"STATION_ID\"] = DivrtID  # Ensure STATION_ID is included\n",
    "\n",
    "                # Convert 'DISCHARGE' to numeric\n",
    "                df[\"DISCHARGE\"] = pd.to_numeric(df[\"DISCHARGE\"], errors=\"coerce\")\n",
    "\n",
    "                # === FLAGGING CRITERIA === #\n",
    "                df[\"FLAG_NEGATIVE\"] = df[\"DISCHARGE\"] < 0\n",
    "                df[\"FLAG_ZERO\"] = df[\"DISCHARGE\"] == 0\n",
    "\n",
    "                # Filter out zero values before statistical computations\n",
    "                df_nonzero = df[df[\"DISCHARGE\"] > 0].copy()\n",
    "\n",
    "                if not df_nonzero.empty:\n",
    "                    # Compute 95th percentile **excluding zero values**\n",
    "                    discharge_95th_percentile = np.percentile(df_nonzero[\"DISCHARGE\"].dropna(), 95)\n",
    "                    \n",
    "                    # Compute IQR **excluding zero values**\n",
    "                    Q1, Q3 = df_nonzero[\"DISCHARGE\"].quantile([0.25, 0.75])\n",
    "                    IQR = Q3 - Q1\n",
    "\n",
    "                    # Compute rate of change **excluding zero values**\n",
    "                    df_nonzero[\"RATE_OF_CHANGE\"] = df_nonzero[\"DISCHARGE\"].diff().abs()\n",
    "                    df = df.merge(df_nonzero[[\"Date\", \"RATE_OF_CHANGE\"]], on=\"Date\", how=\"left\")\n",
    "\n",
    "                    # Compute repeated values >= 4 days **excluding zero values**\n",
    "                    df_nonzero[\"FLAG_REPEATED\"] = df_nonzero[\"DISCHARGE\"].groupby(\n",
    "                        (df_nonzero[\"DISCHARGE\"] != df_nonzero[\"DISCHARGE\"].shift()).cumsum()\n",
    "                    ).transform(\"count\") >= 4\n",
    "\n",
    "                    # Apply Isolation Forest **excluding zero values**\n",
    "                    model = IsolationForest(contamination=0.05, random_state=42)\n",
    "                    df_nonzero[\"OUTLIER_IF\"] = model.fit_predict(df_nonzero[[\"DISCHARGE\"]])\n",
    "                    df_nonzero[\"OUTLIER_IF\"] = df_nonzero[\"OUTLIER_IF\"] == -1  # Convert to boolean\n",
    "                    \n",
    "                    # === Percent Average Deviation (RSD) Outlier Detection === #\n",
    "                    mean_discharge = df_nonzero[\"DISCHARGE\"].mean()  # Compute mean excluding zero values\n",
    "                    df[\"PERCENT_DEV\"] = ((df[\"DISCHARGE\"] - mean_discharge).abs() / mean_discharge) * 100  # Compute percent deviation\n",
    "                    \n",
    "                    # Set a threshold for extreme outliers (e.g., above 1000%)\n",
    "                    threshold = 1000  # Modify as needed\n",
    "                    df[\"FLAG_RSD\"] = (df[\"PERCENT_DEV\"] > threshold) & (df[\"DISCHARGE\"] != 0)\n",
    "                    \n",
    "                    # Merge non-zero flags back into main DataFrame\n",
    "                    df = df.merge(df_nonzero[[\"Date\", \"OUTLIER_IF\", \"FLAG_REPEATED\"]], on=\"Date\", how=\"left\")\n",
    "                else:\n",
    "                    discharge_95th_percentile = 0\n",
    "                    IQR = 0\n",
    "                    df[\"RATE_OF_CHANGE\"] = np.nan\n",
    "                    df[\"OUTLIER_IF\"] = False\n",
    "                    df[\"FLAG_REPEATED\"] = False\n",
    "                    df[\"PERCENT_DEV\"] = np.nan\n",
    "                    df[\"FLAG_RSD\"] = False\n",
    "\n",
    "                # Apply flagging based on computed values\n",
    "                df[\"FLAG_Discharge\"] = df[\"DISCHARGE\"] > discharge_95th_percentile\n",
    "                df[\"FLAG_IQR\"] = (df[\"DISCHARGE\"] < Q1 - 1.5 * IQR) | (df[\"DISCHARGE\"] > Q3 + 1.5 * IQR)\n",
    "                df[\"FLAG_RoC\"] = df[\"RATE_OF_CHANGE\"] > discharge_95th_percentile\n",
    "\n",
    "                df[\"FLAGGED\"] = df[\n",
    "                    [\"FLAG_NEGATIVE\", \"FLAG_ZERO\", \"FLAG_REPEATED\", \"FLAG_IQR\", \"OUTLIER_IF\", \"FLAG_Discharge\", \"FLAG_RoC\", \"FLAG_RSD\"]\n",
    "                ].any(axis=1)\n",
    "\n",
    "                # Create summary for the current station\n",
    "                station_summary = {\n",
    "                    \"STATION_ID\": DivrtID,\n",
    "                    \"TOTAL_RECORDS\": len(df),\n",
    "                    \"TOTAL_NEGATIVE\": df[\"FLAG_NEGATIVE\"].sum(),\n",
    "                    \"TOTAL_ZERO\": df[\"FLAG_ZERO\"].sum(),\n",
    "                    \"TOTAL_95th\": df[\"FLAG_Discharge\"].sum(),\n",
    "                    \"TOTAL_IQR\": df[\"FLAG_IQR\"].sum(),\n",
    "                    \"TOTAL_RoC\": df[\"FLAG_RoC\"].sum(),\n",
    "                    \"TOTAL_REPEATED\": df[\"FLAG_REPEATED\"].sum(),\n",
    "                    \"TOTAL_IF\": df[\"OUTLIER_IF\"].sum(),\n",
    "                    \"TOTAL_RSD\": df[\"FLAG_RSD\"].sum(),\n",
    "                    \"TOTAL_FLAGGED\": df[\"FLAGGED\"].sum() }\n",
    "                \n",
    "\n",
    "                # Append the summary to results\n",
    "                df_results = pd.concat([df_results, pd.DataFrame([station_summary])], ignore_index=True)\n",
    "        \n",
    "        pbar.update(1)\n",
    "\n",
    "# Merge metadata with results on STATION_ID\n",
    "merged_df = pd.merge(filtered_metadata, df_results, on=\"STATION_ID\", how=\"left\")\n",
    "\n",
    "# Save the final merged CSV\n",
    "output_filename = \"merged_3.0_839_station_metadata_flagging_criteria_results.csv\"\n",
    "merged_df.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"Final merged data saved as {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e672cb3a-1cf9-4520-9e89-f4b13a27b0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Stations: 100%|██████████| 10/10 [00:09<00:00,  1.00station/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time Taken: 9.98 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import time\n",
    "from tqdm import tqdm  # Progress bar\n",
    "\n",
    "# Load metadata CSV\n",
    "metadata_path = \"C:\\\\Users\\\\pbenko\\\\Documents\\\\SQL saved scripts\\\\meta_data_for_all_active_systems_for_calculation_20250401(CSV).csv\"\n",
    "metadata_df = pd.read_csv(metadata_path, dtype={\"STATION_ID\": str})  # Ensure STATION_ID is a string\n",
    "\n",
    "# Get the first 10 rows of metadata\n",
    "filtered_metadata = metadata_df.head(10).copy()\n",
    "\n",
    "# Extract STATION_IDs from the first 839 rows\n",
    "site_ids = filtered_metadata[\"STATION_ID\"].tolist()\n",
    "\n",
    "# Initialize results DataFrame\n",
    "df_results = pd.DataFrame()\n",
    "\n",
    "# Start progress bar\n",
    "start_time = time.time()\n",
    "with tqdm(total=len(site_ids), desc=\"Processing Stations\", unit=\"station\") as pbar:\n",
    "    for i, DivrtID in enumerate(site_ids, start=1):\n",
    "        end_date = datetime.today().strftime(\"%Y-%m-%d\")  # Get today's date in YYYY-MM-DD format\n",
    "        api_url = f\"https://www.waterrights.utah.gov/dvrtdb/daily-chart.asp?station_id={DivrtID}&end_date={end_date}&f=json\"\n",
    "\n",
    "        response = requests.get(api_url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if \"data\" in data:\n",
    "                df = pd.DataFrame(data[\"data\"], columns=[\"date\", \"value\"])\n",
    "                df.rename(columns={\"date\": \"Date\", \"value\": \"DISCHARGE\"}, inplace=True)\n",
    "                df[\"STATION_ID\"] = DivrtID  # Ensure STATION_ID is included\n",
    "\n",
    "                # Convert 'DISCHARGE' to numeric\n",
    "                df[\"DISCHARGE\"] = pd.to_numeric(df[\"DISCHARGE\"], errors=\"coerce\")\n",
    "\n",
    "                # === FLAGGING CRITERIA === #\n",
    "                df[\"FLAG_NEGATIVE\"] = df[\"DISCHARGE\"] < 0\n",
    "                df[\"FLAG_ZERO\"] = df[\"DISCHARGE\"] == 0\n",
    "\n",
    "                # Filter out zero values before statistical computations\n",
    "                df_nonzero = df[df[\"DISCHARGE\"] > 0].copy()\n",
    "\n",
    "                if not df_nonzero.empty:\n",
    "                    # Compute 95th percentile **excluding zero values**\n",
    "                    discharge_95th_percentile = np.percentile(df_nonzero[\"DISCHARGE\"].dropna(), 95)\n",
    "                    \n",
    "                    # Compute IQR **excluding zero values**\n",
    "                    Q1, Q3 = df_nonzero[\"DISCHARGE\"].quantile([0.25, 0.75])\n",
    "                    IQR = Q3 - Q1\n",
    "\n",
    "                    # Compute rate of change **excluding zero values**\n",
    "                    df_nonzero[\"RATE_OF_CHANGE\"] = df_nonzero[\"DISCHARGE\"].diff().abs()\n",
    "                    df = df.merge(df_nonzero[[\"Date\", \"RATE_OF_CHANGE\"]], on=\"Date\", how=\"left\")\n",
    "\n",
    "                    # Compute repeated values >= 4 days **excluding zero values**\n",
    "                    df_nonzero[\"FLAG_REPEATED\"] = df_nonzero[\"DISCHARGE\"].groupby(\n",
    "                        (df_nonzero[\"DISCHARGE\"] != df_nonzero[\"DISCHARGE\"].shift()).cumsum()\n",
    "                    ).transform(\"count\") >= 4\n",
    "\n",
    "                    # Apply Isolation Forest **excluding zero values**\n",
    "                    model = IsolationForest(contamination=0.05, random_state=42)\n",
    "                    df_nonzero[\"OUTLIER_IF\"] = model.fit_predict(df_nonzero[[\"DISCHARGE\"]])\n",
    "                    df_nonzero[\"OUTLIER_IF\"] = df_nonzero[\"OUTLIER_IF\"] == -1  # Convert to boolean\n",
    "                    \n",
    "                    # === Percent Average Deviation (RSD) Outlier Detection === #\n",
    "                    mean_discharge = df_nonzero[\"DISCHARGE\"].mean()  # Compute mean excluding zero values\n",
    "                    df[\"PERCENT_DEV\"] = ((df[\"DISCHARGE\"] - mean_discharge).abs() / mean_discharge) * 100  # Compute percent deviation\n",
    "                    \n",
    "                    # Set a threshold for extreme outliers (e.g., above 1000%)\n",
    "                    threshold = 1000  # Modify as needed\n",
    "                    df[\"FLAG_RSD\"] = (df[\"PERCENT_DEV\"] > threshold) & (df[\"DISCHARGE\"] != 0)\n",
    "                    \n",
    "                    # Merge non-zero flags back into main DataFrame\n",
    "                    df = df.merge(df_nonzero[[\"Date\", \"OUTLIER_IF\", \"FLAG_REPEATED\"]], on=\"Date\", how=\"left\")\n",
    "                else:\n",
    "                    discharge_95th_percentile = 0\n",
    "                    IQR = 0\n",
    "                    df[\"RATE_OF_CHANGE\"] = np.nan\n",
    "                    df[\"OUTLIER_IF\"] = False\n",
    "                    df[\"FLAG_REPEATED\"] = False\n",
    "                    df[\"PERCENT_DEV\"] = np.nan\n",
    "                    df[\"FLAG_RSD\"] = False\n",
    "\n",
    "                # Apply flagging based on computed values\n",
    "                df[\"FLAG_Discharge\"] = df[\"DISCHARGE\"] > discharge_95th_percentile\n",
    "                df[\"FLAG_IQR\"] = (df[\"DISCHARGE\"] < Q1 - 1.5 * IQR) | (df[\"DISCHARGE\"] > Q3 + 1.5 * IQR)\n",
    "                df[\"FLAG_RoC\"] = df[\"RATE_OF_CHANGE\"] > discharge_95th_percentile\n",
    "\n",
    "                df[\"FLAGGED\"] = df[\n",
    "                    [\"FLAG_NEGATIVE\", \"FLAG_ZERO\", \"FLAG_REPEATED\", \"FLAG_IQR\", \"OUTLIER_IF\", \"FLAG_Discharge\", \"FLAG_RoC\", \"FLAG_RSD\"]\n",
    "                ].any(axis=1)\n",
    "\n",
    "                # Create summary for the current station\n",
    "                total_flagged = df[\"FLAGGED\"].sum()  # Add this line to calculate total_flagged\n",
    "\n",
    "                station_summary = {\n",
    "                    \"STATION_ID\": DivrtID,\n",
    "                    \"TOTAL_RECORDS\": len(df),\n",
    "                    \"TOTAL_NEGATIVE\": df[\"FLAG_NEGATIVE\"].sum(),\n",
    "                    \"TOTAL_ZERO\": df[\"FLAG_ZERO\"].sum(),\n",
    "                    \"TOTAL_95th\": df[\"FLAG_Discharge\"].sum(),\n",
    "                    \"TOTAL_IQR\": df[\"FLAG_IQR\"].sum(),\n",
    "                    \"TOTAL_RoC\": df[\"FLAG_RoC\"].sum(),\n",
    "                    \"TOTAL_REPEATED\": df[\"FLAG_REPEATED\"].sum(),\n",
    "                    \"TOTAL_IF\": df[\"OUTLIER_IF\"].sum(),\n",
    "                    \"TOTAL_RSD\": df[\"FLAG_RSD\"].sum(),\n",
    "                    \"TOTAL_FLAGGED\": df[\"FLAGGED\"].sum(),\n",
    "                    # Ratios\n",
    "                    \"NEGATIVE_RATIO\": (df[\"FLAG_NEGATIVE\"].sum() / total_flagged) * 100 if total_flagged else 0,\n",
    "                    \"ZERO_RATIO\": (df[\"FLAG_ZERO\"].sum() / total_flagged) * 100 if total_flagged else 0,\n",
    "                    \"DISCHARGE_RATIO\": (df[\"FLAG_Discharge\"].sum() / total_flagged) * 100 if total_flagged else 0,\n",
    "                    \"IQR_RATIO\": (df[\"FLAG_IQR\"].sum() / total_flagged) * 100 if total_flagged else 0,\n",
    "                    \"RoC_RATIO\": (df[\"FLAG_RoC\"].sum() / total_flagged) * 100 if total_flagged else 0,\n",
    "                    \"REPEATED_RATIO\": (df[\"FLAG_REPEATED\"].sum() / total_flagged) * 100 if total_flagged else 0,\n",
    "                    \"IF_RATIO\": (df[\"OUTLIER_IF\"].sum() / total_flagged) * 100 if total_flagged else 0,\n",
    "                    \"RSD_RATIO\": (df[\"FLAG_RSD\"].sum() / total_flagged) * 100 if total_flagged else 0,\n",
    "                }\n",
    "\n",
    "                # Define and separate the two seasons\n",
    "                df['Date'] = pd.to_datetime(df['Date'])\n",
    "                \n",
    "                # Define Irrigation season: April 1st to October 1st\n",
    "                df[\"SEASON\"] = np.where(\n",
    "                    ((df[\"Date\"].dt.month == 4) & (df[\"Date\"].dt.day >= 1)) |  # April 1st onwards\n",
    "                    ((df[\"Date\"].dt.month == 10) & (df[\"Date\"].dt.day <= 1)),  # October 1st\n",
    "                    \"Irrigation\", \n",
    "                    \"Non-Irrigation\"\n",
    "                )\n",
    "\n",
    "                # Irrigation Season Processing\n",
    "                df_irrigation = df[df[\"SEASON\"] == \"Irrigation\"]\n",
    "                \n",
    "                # Compute flagging counts for Irrigation Season\n",
    "                seasonal_flagging_irrigation = df_irrigation.groupby(\"SEASON\").agg({\n",
    "                    'FLAG_NEGATIVE': 'sum',\n",
    "                    'FLAG_ZERO': 'sum',\n",
    "                    'FLAG_Discharge': 'sum',\n",
    "                    'FLAG_IQR': 'sum',\n",
    "                    'FLAG_RoC': 'sum',\n",
    "                    'FLAG_REPEATED': 'sum',\n",
    "                    'OUTLIER_IF': 'sum',\n",
    "                    'FLAG_RSD': 'sum',\n",
    "                    'FLAGGED': 'sum'\n",
    "                }).reset_index()\n",
    "\n",
    "                # Non-Irrigation Season Processing\n",
    "                df_non_irrigation = df[df[\"SEASON\"] == \"Non-Irrigation\"]\n",
    "                \n",
    "                # Compute flagging counts for Non-Irrigation Season\n",
    "                seasonal_flagging_non_irrigation = df_non_irrigation.groupby(\"SEASON\").agg({\n",
    "                    'FLAG_NEGATIVE': 'sum',\n",
    "                    'FLAG_ZERO': 'sum',\n",
    "                    'FLAG_Discharge': 'sum',\n",
    "                    'FLAG_IQR': 'sum',\n",
    "                    'FLAG_RoC': 'sum',\n",
    "                    'FLAG_REPEATED': 'sum',\n",
    "                    'OUTLIER_IF': 'sum',\n",
    "                    'FLAG_RSD': 'sum',\n",
    "                    'FLAGGED': 'sum'\n",
    "                }).reset_index()\n",
    "\n",
    "                # Append the summary to results\n",
    "                df_results = pd.concat([df_results, pd.DataFrame([station_summary])], ignore_index=True)\n",
    "        \n",
    "        pbar.update(1)\n",
    "\n",
    "# Merge metadata with results on STATION_ID\n",
    "merged_df = pd.merge(filtered_metadata, df_results, on=\"STATION_ID\", how=\"left\")\n",
    "\n",
    "# Save the final merged CSV\n",
    "output_filename = \"merged_3.0_10_station_metadata_flagging_criteria_results.csv\"\n",
    "merged_df.to_csv(output_filename, index=False)\n",
    "\n",
    "# Time taken for processing\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Total Time Taken: {elapsed_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dc536f2-2bca-439f-a0b4-0aab4ac49a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Stations: 100%|██████████| 10/10 [00:09<00:00,  1.10station/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final merged data saved as merged_seasonal_flagging_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import time\n",
    "from tqdm import tqdm  # Progress bar\n",
    "\n",
    "# Load metadata CSV\n",
    "metadata_path = \"C:\\\\Users\\\\pbenko\\\\Documents\\\\SQL saved scripts\\\\meta_data_for_all_active_systems_for_calculation_20250401(CSV).csv\"\n",
    "metadata_df = pd.read_csv(metadata_path, dtype={\"STATION_ID\": str})  # Ensure STATION_ID is a string\n",
    "\n",
    "# Get the first 10 rows of metadata\n",
    "filtered_metadata = metadata_df.head(10).copy()\n",
    "\n",
    "# Extract STATION_IDs from the first 839 rows\n",
    "site_ids = filtered_metadata[\"STATION_ID\"].tolist()\n",
    "\n",
    "# Initialize results DataFrame\n",
    "df_results = pd.DataFrame()\n",
    "\n",
    "# Start progress bar\n",
    "start_time = time.time()\n",
    "with tqdm(total=len(site_ids), desc=\"Processing Stations\", unit=\"station\") as pbar:\n",
    "    for i, DivrtID in enumerate(site_ids, start=1):\n",
    "        end_date = datetime.today().strftime(\"%Y-%m-%d\")  # Get today's date in YYYY-MM-DD format\n",
    "        api_url = f\"https://www.waterrights.utah.gov/dvrtdb/daily-chart.asp?station_id={DivrtID}&end_date={end_date}&f=json\"\n",
    "\n",
    "        response = requests.get(api_url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if \"data\" in data:\n",
    "                df = pd.DataFrame(data[\"data\"], columns=[\"date\", \"value\"])\n",
    "                df.rename(columns={\"date\": \"Date\", \"value\": \"DISCHARGE\"}, inplace=True)\n",
    "                df[\"STATION_ID\"] = DivrtID  # Ensure STATION_ID is included\n",
    "                \n",
    "                # Convert 'Date' to datetime format\n",
    "                df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "                \n",
    "                # Identify irrigation and non-irrigation season\n",
    "                df[\"SEASON\"] = np.where(\n",
    "                    df[\"Date\"].dt.month.between(4, 9) | ((df[\"Date\"].dt.month == 10) & (df[\"Date\"].dt.day == 1)),\n",
    "                    \"Irrigation Season\", \"Non-Irrigation Season\"\n",
    "                )\n",
    "                \n",
    "                # Convert 'DISCHARGE' to numeric\n",
    "                df[\"DISCHARGE\"] = pd.to_numeric(df[\"DISCHARGE\"], errors=\"coerce\")\n",
    "                \n",
    "                # === FLAGGING CRITERIA === #\n",
    "                df[\"FLAG_NEGATIVE\"] = df[\"DISCHARGE\"] < 0\n",
    "                df[\"FLAG_ZERO\"] = df[\"DISCHARGE\"] == 0\n",
    "                \n",
    "                # Filter out zero values before statistical computations\n",
    "                df_nonzero = df[df[\"DISCHARGE\"] > 0].copy()\n",
    "\n",
    "                if not df_nonzero.empty:\n",
    "                    Q1, Q3 = df_nonzero[\"DISCHARGE\"].quantile([0.25, 0.75])\n",
    "                    IQR = Q3 - Q1\n",
    "                    discharge_95th_percentile = np.percentile(df_nonzero[\"DISCHARGE\"].dropna(), 95)\n",
    "                    \n",
    "                    df_nonzero[\"RATE_OF_CHANGE\"] = df_nonzero[\"DISCHARGE\"].diff().abs()\n",
    "                    df = df.merge(df_nonzero[[\"Date\", \"RATE_OF_CHANGE\"]], on=\"Date\", how=\"left\")\n",
    "                    \n",
    "                    df_nonzero[\"FLAG_REPEATED\"] = df_nonzero[\"DISCHARGE\"].groupby(\n",
    "                        (df_nonzero[\"DISCHARGE\"] != df_nonzero[\"DISCHARGE\"].shift()).cumsum()\n",
    "                    ).transform(\"count\") >= 4\n",
    "                    \n",
    "                    model = IsolationForest(contamination=0.05, random_state=42)\n",
    "                    df_nonzero[\"OUTLIER_IF\"] = model.fit_predict(df_nonzero[[\"DISCHARGE\"]])\n",
    "                    df_nonzero[\"OUTLIER_IF\"] = df_nonzero[\"OUTLIER_IF\"] == -1\n",
    "                    \n",
    "                    mean_discharge = df_nonzero[\"DISCHARGE\"].mean()\n",
    "                    df[\"PERCENT_DEV\"] = ((df[\"DISCHARGE\"] - mean_discharge).abs() / mean_discharge) * 100\n",
    "                    \n",
    "                    threshold = 1000\n",
    "                    df[\"FLAG_RSD\"] = (df[\"PERCENT_DEV\"] > threshold) & (df[\"DISCHARGE\"] != 0)\n",
    "                    \n",
    "                    df = df.merge(df_nonzero[[\"Date\", \"OUTLIER_IF\", \"FLAG_REPEATED\"]], on=\"Date\", how=\"left\")\n",
    "                else:\n",
    "                    discharge_95th_percentile = 0\n",
    "                    IQR = 0\n",
    "                    df[\"RATE_OF_CHANGE\"] = np.nan\n",
    "                    df[\"OUTLIER_IF\"] = False\n",
    "                    df[\"FLAG_REPEATED\"] = False\n",
    "                    df[\"PERCENT_DEV\"] = np.nan\n",
    "                    df[\"FLAG_RSD\"] = False\n",
    "\n",
    "                df[\"FLAG_Discharge\"] = df[\"DISCHARGE\"] > discharge_95th_percentile\n",
    "                df[\"FLAG_IQR\"] = (df[\"DISCHARGE\"] < Q1 - 1.5 * IQR) | (df[\"DISCHARGE\"] > Q3 + 1.5 * IQR)\n",
    "                df[\"FLAG_RoC\"] = df[\"RATE_OF_CHANGE\"] > discharge_95th_percentile\n",
    "                \n",
    "                df[\"FLAGGED\"] = df[\n",
    "                    [\"FLAG_NEGATIVE\", \"FLAG_ZERO\", \"FLAG_REPEATED\", \"FLAG_IQR\", \"OUTLIER_IF\", \"FLAG_Discharge\", \"FLAG_RoC\", \"FLAG_RSD\"]\n",
    "                ].any(axis=1)\n",
    "                \n",
    "                # Count flagged records for each season\n",
    "                season_summary = df.groupby(\"SEASON\")[\"FLAGGED\"].sum().to_dict()\n",
    "                \n",
    "                station_summary = {\n",
    "                    \"STATION_ID\": DivrtID,\n",
    "                    \"TOTAL_RECORDS\": len(df),\n",
    "                    \"TOTAL_FLAGGED\": df[\"FLAGGED\"].sum(),\n",
    "                    \"TOTAL_FLAGGED_IRRIGATION\": season_summary.get(\"Irrigation Season\", 0),\n",
    "                    \"TOTAL_FLAGGED_NON_IRRIGATION\": season_summary.get(\"Non-Irrigation Season\", 0)\n",
    "                }\n",
    "                \n",
    "                df_results = pd.concat([df_results, pd.DataFrame([station_summary])], ignore_index=True)\n",
    "        \n",
    "        pbar.update(1)\n",
    "\n",
    "merged_df = pd.merge(filtered_metadata, df_results, on=\"STATION_ID\", how=\"left\")\n",
    "output_filename = \"merged_seasonal_flagging_results.csv\"\n",
    "merged_df.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"Final merged data saved as {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602d2e0b-e53c-498f-a848-bf2f646276e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
