{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f62d727-2bc5-4e4f-a22d-2104a86bc181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import time\n",
    "from tqdm import tqdm  # Progress bar\n",
    "\n",
    "# Load metadata CSV\n",
    "metadata_path = \"C:\\\\Users\\\\pbenko\\\\Documents\\\\SQL saved scripts\\\\meta_data_for_all_active_systems_for_calculation_20250401(CSV).csv\"\n",
    "metadata_df = pd.read_csv(metadata_path, dtype={\"STATION_ID\": str})  # Ensure STATION_ID is a string\n",
    "\n",
    "# Get the first 840 rows of metadata\n",
    "filtered_metadata = metadata_df.head(840).copy()\n",
    "\n",
    "# Extract STATION_IDs from the first 839 rows\n",
    "site_ids = filtered_metadata[\"STATION_ID\"].tolist()\n",
    "\n",
    "# Initialize results DataFrame\n",
    "df_results = pd.DataFrame()\n",
    "\n",
    "# Start progress bar\n",
    "start_time = time.time()\n",
    "with tqdm(total=len(site_ids), desc=\"Processing Stations\", unit=\"station\") as pbar:\n",
    "    for i, DivrtID in enumerate(site_ids, start=1):\n",
    "        end_date = datetime.today().strftime(\"%Y-%m-%d\")  # Get today's date in YYYY-MM-DD format\n",
    "        api_url = f\"https://www.waterrights.utah.gov/dvrtdb/daily-chart.asp?station_id={DivrtID}&end_date={end_date}&f=json\"\n",
    "\n",
    "        response = requests.get(api_url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if \"data\" in data:\n",
    "                df = pd.DataFrame(data[\"data\"], columns=[\"date\", \"value\"])\n",
    "                df.rename(columns={\"date\": \"Date\", \"value\": \"DISCHARGE\"}, inplace=True)\n",
    "                df[\"STATION_ID\"] = DivrtID  # Ensure STATION_ID is included\n",
    "\n",
    "                # Convert 'DISCHARGE' to numeric\n",
    "                df[\"DISCHARGE\"] = pd.to_numeric(df[\"DISCHARGE\"], errors=\"coerce\")\n",
    "\n",
    "                # === FLAGGING CRITERIA === #\n",
    "                df[\"FLAG_NEGATIVE\"] = df[\"DISCHARGE\"] < 0\n",
    "                df[\"FLAG_ZERO\"] = df[\"DISCHARGE\"] == 0\n",
    "\n",
    "                # Filter out zero values before statistical computations\n",
    "                df_nonzero = df[df[\"DISCHARGE\"] > 0].copy()\n",
    "\n",
    "                if not df_nonzero.empty:\n",
    "                    # Compute 95th percentile **excluding zero values**\n",
    "                    discharge_95th_percentile = np.percentile(df_nonzero[\"DISCHARGE\"].dropna(), 95)\n",
    "                    \n",
    "                    # Compute IQR **excluding zero values**\n",
    "                    Q1, Q3 = df_nonzero[\"DISCHARGE\"].quantile([0.25, 0.75])\n",
    "                    IQR = Q3 - Q1\n",
    "\n",
    "                    # Compute rate of change **excluding zero values**\n",
    "                    df_nonzero[\"RATE_OF_CHANGE\"] = df_nonzero[\"DISCHARGE\"].diff().abs()\n",
    "                    df = df.merge(df_nonzero[[\"Date\", \"RATE_OF_CHANGE\"]], on=\"Date\", how=\"left\")\n",
    "\n",
    "                    # Compute repeated values >= 4 days **excluding zero values**\n",
    "                    df_nonzero[\"FLAG_REPEATED\"] = df_nonzero[\"DISCHARGE\"].groupby(\n",
    "                        (df_nonzero[\"DISCHARGE\"] != df_nonzero[\"DISCHARGE\"].shift()).cumsum()\n",
    "                    ).transform(\"count\") >= 4\n",
    "\n",
    "                    # Apply Isolation Forest **excluding zero values**\n",
    "                    model = IsolationForest(contamination=0.05, random_state=42)\n",
    "                    df_nonzero[\"OUTLIER_IF\"] = model.fit_predict(df_nonzero[[\"DISCHARGE\"]])\n",
    "                    df_nonzero[\"OUTLIER_IF\"] = df_nonzero[\"OUTLIER_IF\"] == -1  # Convert to boolean\n",
    "                    \n",
    "                    # === Percent Average Deviation (RSD) Outlier Detection === #\n",
    "                    mean_discharge = df_nonzero[\"DISCHARGE\"].mean()  # Compute mean excluding zero values\n",
    "                    df[\"PERCENT_DEV\"] = ((df[\"DISCHARGE\"] - mean_discharge).abs() / mean_discharge) * 100  # Compute percent deviation\n",
    "                    \n",
    "                    # Set a threshold for extreme outliers (e.g., above 1000%)\n",
    "                    threshold = 1000  # Modify as needed\n",
    "                    df[\"FLAG_RSD\"] = (df[\"PERCENT_DEV\"] > threshold) & (df[\"DISCHARGE\"] != 0)\n",
    "                    \n",
    "                    # Merge non-zero flags back into main DataFrame\n",
    "                    df = df.merge(df_nonzero[[\"Date\", \"OUTLIER_IF\", \"FLAG_REPEATED\"]], on=\"Date\", how=\"left\")\n",
    "                else:\n",
    "                    discharge_95th_percentile = 0\n",
    "                    IQR = 0\n",
    "                    df[\"RATE_OF_CHANGE\"] = np.nan\n",
    "                    df[\"OUTLIER_IF\"] = False\n",
    "                    df[\"FLAG_REPEATED\"] = False\n",
    "                    df[\"PERCENT_DEV\"] = np.nan\n",
    "                    df[\"FLAG_RSD\"] = False\n",
    "\n",
    "                # Apply flagging based on computed values\n",
    "                df[\"FLAG_Discharge\"] = df[\"DISCHARGE\"] > discharge_95th_percentile\n",
    "                df[\"FLAG_IQR\"] = (df[\"DISCHARGE\"] < Q1 - 1.5 * IQR) | (df[\"DISCHARGE\"] > Q3 + 1.5 * IQR)\n",
    "                df[\"FLAG_RoC\"] = df[\"RATE_OF_CHANGE\"] > discharge_95th_percentile\n",
    "\n",
    "                df[\"FLAGGED\"] = df[\n",
    "                    [\"FLAG_NEGATIVE\", \"FLAG_ZERO\", \"FLAG_REPEATED\", \"FLAG_IQR\", \"OUTLIER_IF\", \"FLAG_Discharge\", \"FLAG_RoC\", \"FLAG_RSD\"]\n",
    "                ].any(axis=1)\n",
    "\n",
    "                # Create summary for the current station\n",
    "                station_summary = {\n",
    "                    \"STATION_ID\": DivrtID,\n",
    "                    \"TOTAL_RECORDS\": len(df),\n",
    "                    \"TOTAL_NEGATIVE\": df[\"FLAG_NEGATIVE\"].sum(),\n",
    "                    \"TOTAL_ZERO\": df[\"FLAG_ZERO\"].sum(),\n",
    "                    \"TOTAL_95th\": df[\"FLAG_Discharge\"].sum(),\n",
    "                    \"TOTAL_IQR\": df[\"FLAG_IQR\"].sum(),\n",
    "                    \"TOTAL_RoC\": df[\"FLAG_RoC\"].sum(),\n",
    "                    \"TOTAL_REPEATED\": df[\"FLAG_REPEATED\"].sum(),\n",
    "                    \"TOTAL_IF\": df[\"OUTLIER_IF\"].sum(),\n",
    "                    \"TOTAL_RSD\": df[\"FLAG_RSD\"].sum(),\n",
    "                    \"TOTAL_FLAGGED\": df[\"FLAGGED\"].sum() }\n",
    "                \n",
    "\n",
    "                # Append the summary to results\n",
    "                df_results = pd.concat([df_results, pd.DataFrame([station_summary])], ignore_index=True)\n",
    "        \n",
    "        pbar.update(1)\n",
    "\n",
    "# Merge metadata with results on STATION_ID\n",
    "merged_df = pd.merge(filtered_metadata, df_results, on=\"STATION_ID\", how=\"left\")\n",
    "\n",
    "# Save the final merged CSV\n",
    "output_filename = \"merged_3.0_839_station_metadata_flagging_criteria_results.csv\"\n",
    "merged_df.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"Final merged data saved as {output_filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
