{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0127f89f-9c8a-482a-8469-4e228f8c1517",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Stations: 100%|██████████| 839/839 [09:21<00:00,  1.49station/s, ETA (min)=0.00] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final merged data saved as merged_840_station_metadata_flagging_criteria_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import time\n",
    "from tqdm import tqdm  # Progress bar\n",
    "\n",
    "# Load metadata CSV\n",
    "metadata_path = \"C:\\\\Users\\\\pbenko\\\\Documents\\\\SQL saved scripts\\\\meta_data_for_all_active_systems_for_calculation_20250401(CSV).csv\"\n",
    "metadata_df = pd.read_csv(metadata_path, dtype={\"STATION_ID\": str})  # Ensure STATION_ID is a string\n",
    "\n",
    "# Get the first 840 rows of metadata\n",
    "filtered_metadata = metadata_df.head(840).copy()\n",
    "\n",
    "# Extract STATION_IDs from the first 840 rows\n",
    "site_ids = filtered_metadata[\"STATION_ID\"].tolist()\n",
    "\n",
    "# Initialize results DataFrame\n",
    "df_results = pd.DataFrame()\n",
    "\n",
    "# Start progress bar\n",
    "start_time = time.time()\n",
    "with tqdm(total=len(site_ids), desc=\"Processing Stations\", unit=\"station\") as pbar:\n",
    "    for i, DivrtID in enumerate(site_ids, start=1):\n",
    "        end_date = datetime.today().strftime(\"%Y-%m-%d\")  # Get today's date in YYYY-MM-DD format\n",
    "        api_url = f\"https://www.waterrights.utah.gov/dvrtdb/daily-chart.asp?station_id={DivrtID}&end_date={end_date}&f=json\"\n",
    "\n",
    "        response = requests.get(api_url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if \"data\" in data:\n",
    "                df = pd.DataFrame(data[\"data\"], columns=[\"date\", \"value\"])\n",
    "                df.rename(columns={\"date\": \"Date\", \"value\": \"DISCHARGE\"}, inplace=True)\n",
    "                df[\"STATION_ID\"] = DivrtID  # Ensure STATION_ID is included\n",
    "\n",
    "                # Convert 'DISCHARGE' to numeric\n",
    "                df[\"DISCHARGE\"] = pd.to_numeric(df[\"DISCHARGE\"], errors=\"coerce\")\n",
    "\n",
    "                # === FLAGGING CRITERIA === #\n",
    "                df[\"FLAG_NEGATIVE\"] = df[\"DISCHARGE\"] < 0\n",
    "                df[\"FLAG_ZERO\"] = df[\"DISCHARGE\"] == 0\n",
    "\n",
    "                # Filter out zero values before statistical computations\n",
    "                df_nonzero = df[df[\"DISCHARGE\"] > 0].copy()\n",
    "\n",
    "                if not df_nonzero.empty:\n",
    "                    # Compute 95th percentile **excluding zero values**\n",
    "                    discharge_95th_percentile = np.percentile(df_nonzero[\"DISCHARGE\"].dropna(), 95)\n",
    "                    \n",
    "                    # Compute IQR **excluding zero values**\n",
    "                    Q1, Q3 = df_nonzero[\"DISCHARGE\"].quantile([0.25, 0.75])\n",
    "                    IQR = Q3 - Q1\n",
    "\n",
    "                    # Compute rate of change **excluding zero values**\n",
    "                    df_nonzero[\"RATE_OF_CHANGE\"] = df_nonzero[\"DISCHARGE\"].diff().abs()\n",
    "                    df = df.merge(df_nonzero[[\"Date\", \"RATE_OF_CHANGE\"]], on=\"Date\", how=\"left\")\n",
    "\n",
    "                    # Compute repeated values **excluding zero values**\n",
    "                    df_nonzero[\"FLAG_REPEATED\"] = df_nonzero[\"DISCHARGE\"].groupby(\n",
    "                        (df_nonzero[\"DISCHARGE\"] != df_nonzero[\"DISCHARGE\"].shift()).cumsum()\n",
    "                    ).transform(\"count\") >= 3\n",
    "\n",
    "                    # Apply Isolation Forest **excluding zero values**\n",
    "                    model = IsolationForest(contamination=0.05, random_state=42)\n",
    "                    df_nonzero[\"OUTLIER_IF\"] = model.fit_predict(df_nonzero[[\"DISCHARGE\"]])\n",
    "                    df_nonzero[\"OUTLIER_IF\"] = df_nonzero[\"OUTLIER_IF\"] == -1  # Convert to boolean\n",
    "                    \n",
    "                    # Merge non-zero flags back into main DataFrame\n",
    "                    df = df.merge(df_nonzero[[\"Date\", \"OUTLIER_IF\", \"FLAG_REPEATED\"]], on=\"Date\", how=\"left\")\n",
    "                else:\n",
    "                    discharge_95th_percentile = 0\n",
    "                    IQR = 0\n",
    "                    df[\"RATE_OF_CHANGE\"] = np.nan\n",
    "                    df[\"OUTLIER_IF\"] = False\n",
    "                    df[\"FLAG_REPEATED\"] = False\n",
    "\n",
    "                # Apply flagging based on computed values\n",
    "                df[\"FLAG_Discharge\"] = df[\"DISCHARGE\"] > discharge_95th_percentile\n",
    "                df[\"FLAG_IQR\"] = (df[\"DISCHARGE\"] < Q1 - 1.5 * IQR) | (df[\"DISCHARGE\"] > Q3 + 1.5 * IQR)\n",
    "                df[\"FLAG_RoC\"] = df[\"RATE_OF_CHANGE\"] > discharge_95th_percentile\n",
    "\n",
    "                df[\"FLAGGED\"] = df[\n",
    "                    [\"FLAG_NEGATIVE\", \"FLAG_ZERO\", \"FLAG_REPEATED\", \"FLAG_IQR\", \"OUTLIER_IF\", \"FLAG_Discharge\", \"FLAG_RoC\"]\n",
    "                ].any(axis=1)\n",
    "\n",
    "                # Create summary for the current station\n",
    "                station_summary = {\n",
    "                    \"STATION_ID\": DivrtID,\n",
    "                    \"TOTAL_RECORDS\": len(df),\n",
    "                    \"TOTAL_NEGATIVE\": df[\"FLAG_NEGATIVE\"].sum(),\n",
    "                    \"TOTAL_ZERO\": df[\"FLAG_ZERO\"].sum(),\n",
    "                    \"TOTAL_95th\": df[\"FLAG_Discharge\"].sum(),\n",
    "                    \"TOTAL_IQR\": df[\"FLAG_IQR\"].sum(),\n",
    "                    \"TOTAL_RoC\": df[\"FLAG_RoC\"].sum(),\n",
    "                    \"TOTAL_REPEATED\": df[\"FLAG_REPEATED\"].sum(),\n",
    "                    \"TOTAL_IF\": df[\"OUTLIER_IF\"].sum(),\n",
    "                    \"TOTAL_FLAGGED\": df[\"FLAGGED\"].sum(),\n",
    "                    \"FLAG_RATIO\": f\"{(df['FLAGGED'].sum() / len(df) * 100):.2f}%\" if len(df) > 0 else \"0.00%\",\n",
    "                    \"ZERO_RATIO\": f\"{(df['FLAG_ZERO'].sum() / len(df) * 100):.2f}%\" if len(df) > 0 else \"0.00%\"\n",
    "                }\n",
    "\n",
    "                # Append the summary to results\n",
    "                df_results = pd.concat([df_results, pd.DataFrame([station_summary])], ignore_index=True)\n",
    "            else:\n",
    "                print(f\"Error: 'data' key not found for STATION_ID {DivrtID}\")\n",
    "        else:\n",
    "            print(f\"Error fetching data for STATION_ID {DivrtID}: {response.status_code}\")\n",
    "\n",
    "        # Update progress bar and estimated time\n",
    "        pbar.update(1)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        avg_time_per_station = elapsed_time / i\n",
    "        estimated_time_remaining = avg_time_per_station * (len(site_ids) - i)\n",
    "        pbar.set_postfix({\"ETA (min)\": f\"{estimated_time_remaining / 60:.2f}\"})\n",
    "\n",
    "# Merge metadata with results on STATION_ID\n",
    "merged_df = pd.merge(filtered_metadata, df_results, on=\"STATION_ID\", how=\"left\")\n",
    "\n",
    "# Save the final merged CSV\n",
    "output_filename = \"merged_840_station_metadata_flagging_criteria_results.csv\"\n",
    "merged_df.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"Final merged data saved as {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f08243-5451-4e2b-bc33-922d4cd957b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
