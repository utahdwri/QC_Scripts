{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1b34156-451f-49ad-a8d0-cd4a6e1449b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported to C:\\Users\\pbenko\\Documents\\20250213_distribution_data\\data\\USGS_Utah_Stations\\New_2.0_sorted_combined_usgs_sql_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pbenko\\AppData\\Local\\Temp\\1\\ipykernel_16980\\3456611106.py:90: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_sql = pd.read_sql_query(query, conn)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "import os\n",
    "\n",
    "# Fetch USGS sites including latitude and longitude\n",
    "def get_usgs_sites(state_code='UT'):\n",
    "    url = \"https://waterservices.usgs.gov/nwis/dv/\"\n",
    "    params = {\n",
    "        'format': 'json',\n",
    "        'stateCd': state_code,\n",
    "        'siteStatus': 'all',\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    \n",
    "    # Extract site code, site name, latitude, and longitude\n",
    "    sites = [\n",
    "        (\n",
    "            site.get('sourceInfo', {}).get('siteCode', [{}])[0].get('value', 'Unknown'),\n",
    "            site.get('sourceInfo', {}).get('siteName', 'Unknown'),\n",
    "            site.get('sourceInfo', {}).get('geoLocation', {}).get('geogLocation', {}).get('latitude', 'Unknown'),\n",
    "            site.get('sourceInfo', {}).get('geoLocation', {}).get('geogLocation', {}).get('longitude', 'Unknown')\n",
    "        )\n",
    "        for site in data.get('value', {}).get('timeSeries', [])\n",
    "    ]\n",
    "    \n",
    "    return sites\n",
    "\n",
    "# Fetch SQL data\n",
    "def get_sql_data():\n",
    "    server = 'wrt-sql-prod'\n",
    "    database = 'dvrtDB'\n",
    "    username = 'wrtsqlq'\n",
    "    password = 'guest'\n",
    "    \n",
    "    # Corrected SQL query to get the data\n",
    "    query = \"\"\"\n",
    "    SELECT [COLLECTION_SYSTEM]\n",
    "           ,[collection_sys_description]\n",
    "           ,[STATION_MASTER].[STATION_ID] As MasterStationID\n",
    "           ,[STATION_MASTER].[STATION_NAME] As MasterStationName\n",
    "           ,[COLLECTION_STATIONS].[STATION_NAME] As CollectionStationName\n",
    "           ,[RETRIES]\n",
    "           ,[SEQ_NO]\n",
    "           ,[COMMENTS]\n",
    "           ,LAT\n",
    "           ,LON\n",
    "           ,[STATION_TYPE]\n",
    "           ,[COMMON_DESC]\n",
    "           ,[DIVERTING_WORKS]\n",
    "           ,[MEASURING_DEVICE]\n",
    "           ,[RECORD_RATING]\n",
    "           ,[SYSTEM_NAME]\n",
    "           ,[UNITS_ID]\n",
    "           ,[OWNER_NAME]   \n",
    "           ,[CAPTURE_SEQ_NO]\n",
    "           ,[ANALOG_CHANNEL]\n",
    "           ,[LOW_FLOW]\n",
    "           ,[HIGH_FLOW]\n",
    "           ,[DEVICE_TYPE]\n",
    "           ,[OWNER_PHONE]\n",
    "           ,[REALTIME_INCLUDE]\n",
    "           ,[CORRECTED_DATA]\n",
    "           ,[STATUS]\n",
    "           ,[SYSTEM_GROUP]\n",
    "           ,[SYSTEM_SUBGROUP]\n",
    "           ,[ADDRESS_ID]\n",
    "           ,[DataEntryMethod]\n",
    "           ,[DataLogger]\n",
    "           ,[DatasetType]\n",
    "           ,[SeriesVerifiedBy]\n",
    "           ,[SeriesVerifiedDate]\n",
    "           ,[SiteState]\n",
    "           ,[SiteType]\n",
    "           ,[SiteVerifiedBy]\n",
    "           ,[SiteVerifiedDate]\n",
    "           ,[Telemetry]\n",
    "    FROM [dvrtDB].[dbo].[COLLECTION_STATIONS]\n",
    "    LEFT JOIN [dvrtDB].[dbo].[COLLECTION_SYSTEMS] \n",
    "        ON [COLLECTION_SYSTEMS].[collection_sys_id] = [COLLECTION_STATIONS].[collection_sys_id]\n",
    "    LEFT JOIN [dvrtDB].[dbo].[STATION_MASTER] \n",
    "        ON [STATION_MASTER].[CAPTURE_SEQ_NO] = [COLLECTION_STATIONS].[SEQ_NO]\n",
    "    WHERE [COLLECTION_SYSTEMS].[collection_sys_description] = 'USGS Gage'\n",
    "    ORDER BY [COLLECTION_SYSTEM] ASC\n",
    "    \"\"\"\n",
    "    \n",
    "    with pyodbc.connect(f\"DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={server};DATABASE={database};UID={username};PWD={password}\") as conn:\n",
    "        df_sql = pd.read_sql_query(query, conn)\n",
    "    \n",
    "    return df_sql\n",
    "\n",
    "# Export USGS and SQL data horizontally into a single CSV\n",
    "def export_to_csv():\n",
    "    # Fetch USGS and SQL data\n",
    "    usgs_sites = get_usgs_sites()\n",
    "    df_sql = get_sql_data()\n",
    "\n",
    "    # Convert USGS data into DataFrame\n",
    "    df_usgs = pd.DataFrame(usgs_sites, columns=['Site Code', 'Site Name', 'Latitude', 'Longitude'])\n",
    "\n",
    "    # Remove duplicates from USGS data based on 'Site Code'\n",
    "    df_usgs = df_usgs.drop_duplicates(subset='Site Code', keep='first')\n",
    "\n",
    "    # Sort both dataframes by Site Code (for USGS) and CollectionStationName (for SQL)\n",
    "    df_usgs['Site Code'] = df_usgs['Site Code'].astype(str)  # Ensure it's treated as a string\n",
    "    df_sql['CollectionStationName'] = df_sql['CollectionStationName'].astype(str)  # Ensure it's treated as a string\n",
    "\n",
    "    # Sort both dataframes\n",
    "    df_usgs = df_usgs.sort_values(by='Site Code').reset_index(drop=True)\n",
    "    df_sql = df_sql.sort_values(by='CollectionStationName').reset_index(drop=True)\n",
    "\n",
    "    # Ensure both dataframes have the same number of rows (pad with NaN if necessary)\n",
    "    max_rows = max(len(df_usgs), len(df_sql))\n",
    "    df_usgs = df_usgs.reindex(range(max_rows))\n",
    "    df_sql = df_sql.reindex(range(max_rows))\n",
    "\n",
    "    # Concatenate the dataframes horizontally (USGS data on the left, SQL data on the right)\n",
    "    combined_df = pd.concat([df_usgs, df_sql], axis=1)\n",
    "\n",
    "    # Save the combined DataFrame to CSV in the current working directory\n",
    "    output_path = os.path.join(os.getcwd(), 'New_2.0_sorted_combined_usgs_sql_data.csv')\n",
    "    combined_df.to_csv(output_path, index=False)\n",
    "    print(f\"Data exported to {output_path}\")\n",
    "\n",
    "# Execute the function\n",
    "export_to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0eb3c10-2abb-4266-94e2-ad05161362fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
